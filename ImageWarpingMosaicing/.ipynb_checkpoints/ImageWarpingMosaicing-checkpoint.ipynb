{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c48411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import path\n",
    "from matplotlib.path import Path\n",
    "import skimage.transform as sktr\n",
    "import skimage.color as color\n",
    "import skimage.io as skio\n",
    "from skimage.draw import polygon\n",
    "import scipy.misc\n",
    "from scipy.signal import convolve2d\n",
    "from scipy.ndimage import map_coordinates\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from scipy import interpolate\n",
    "import scipy\n",
    "from pylab import plot, ginput, show, axis\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "from skimage.feature import corner_harris, peak_local_max\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [8, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc36378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveImage(img, name):\n",
    "    if img.dtype == np.float32 or img.dtype == np.float64:\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "    skio.imsave(\"output/\" + name + \".jpg\", img)\n",
    "    \n",
    "def saveDescriptor(descriptor, name):\n",
    "    plt.figure()\n",
    "    plt.imshow(descriptor, cmap='gray')\n",
    "    plt.axis('off') \n",
    "    plt.savefig(\"output/\" + name + \".jpg\", bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "def resizeImage(img, scale):\n",
    "    # Calculate the new dimensions\n",
    "    new_height = int(img.shape[0] * scale)\n",
    "    new_width = int(img.shape[1] * scale)\n",
    "\n",
    "    # Resize the image\n",
    "    resized_image = cv2.resize(img, (new_width, new_height))\n",
    "\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed89b87",
   "metadata": {},
   "source": [
    "# Part A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cf1f60",
   "metadata": {},
   "source": [
    "## Recover Homographies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f530f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining correspondences using: https://inst.eecs.berkeley.edu/~cs194-26/fa22/upload/files/proj3/cs194-26-aex/tool.html\n",
    "\n",
    "img_left = skio.imread(\"data/left_resized.jpg\") / 255\n",
    "img_center = skio.imread(\"data/middle_resized.jpg\") / 255\n",
    "\n",
    "# Trying just LEFT and CENTER\n",
    "with open(\"left_resized_middle_resized.json\", 'r') as file:\n",
    "    correspondences = json.load(file)\n",
    "\n",
    "pts_left = np.array(correspondences['im1Points'])\n",
    "pts_center = np.array(correspondences['im2Points'])\n",
    "\n",
    "\n",
    "print(pts_left)\n",
    "print(pts_left.shape)\n",
    "print(pts_center)\n",
    "print(pts_center.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99a70e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tuning points\n",
    "def ssd(patch1, patch2):\n",
    "    return np.sum((patch1 - patch2) ** 2)\n",
    "\n",
    "def fine_tune_correspondence(img1, img2, pt1, pt2, patch_size=25):\n",
    "    h, w = patch_size, patch_size\n",
    "    half_h, half_w = h // 2, w // 2\n",
    "\n",
    "    # Extract patch from img1\n",
    "    patch_img1 = img1[pt1[1]-half_h:pt1[1]+half_h+1, pt1[0]-half_w:pt1[0]+half_w+1]\n",
    "\n",
    "    min_ssd = float('inf')\n",
    "    best_match = None\n",
    "\n",
    "    # Search in the vicinity of pt2 in img2 for the best match\n",
    "    for y in range(-half_h, half_h+1):\n",
    "        for x in range(-half_w, half_w+1):\n",
    "            y_coord, x_coord = pt2[1] + y, pt2[0] + x\n",
    "            patch_img2 = img2[y_coord-half_h:y_coord+half_h+1, x_coord-half_w:x_coord+half_w+1]\n",
    "            current_ssd = ssd(patch_img1, patch_img2)\n",
    "            if current_ssd < min_ssd:\n",
    "                min_ssd = current_ssd\n",
    "                best_match = (x_coord, y_coord)\n",
    "\n",
    "    return best_match\n",
    "\n",
    "# refined_pts_center = np.array([fine_tune_correspondence(img_left, img_center, pt1, pt2) for pt1, pt2 in zip(pts_left, pts_center)])\n",
    "\n",
    "# print(pts_left)\n",
    "# print(refined_pts_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bbc9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover Homographies\n",
    "def computeH(im1_pts, im2_pts):\n",
    "\n",
    "    im1_pts = np.array(im1_pts, dtype=float)\n",
    "    im2_pts = np.array(im2_pts, dtype=float)\n",
    "\n",
    "    num_points = im1_pts.shape[0]\n",
    "    \n",
    "    A = np.zeros((2 * num_points, 9))\n",
    "\n",
    "    for i in range(num_points):\n",
    "        x, y = im1_pts[i]\n",
    "        x_prime, y_prime = im2_pts[i]\n",
    "\n",
    "        A[2*i] = [-x, -y, -1, 0, 0, 0, x*x_prime, y*x_prime, x_prime]\n",
    "        A[2*i + 1] = [0, 0, 0, -x, -y, -1, x*y_prime, y*y_prime, y_prime]\n",
    "\n",
    "    _, _, Vt = np.linalg.svd(A)\n",
    "    \n",
    "    H = Vt[-1].reshape(3, 3)\n",
    "\n",
    "    # Normalize H\n",
    "    H /= H[2, 2]\n",
    "\n",
    "    return H\n",
    "\n",
    "# H = computeH(pts_left, refined_pts_center)\n",
    "# print(H)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559d0cc3",
   "metadata": {},
   "source": [
    "## Warp Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a51007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warpImage(im, H, name):\n",
    "    h, w, _ = im.shape\n",
    "\n",
    "    corners = np.array([\n",
    "        [0, 0, 1],\n",
    "        [w-1, 0, 1],\n",
    "        [w-1, h-1, 1],\n",
    "        [0, h-1, 1]\n",
    "    ])\n",
    "\n",
    "    # Transform corners using homography\n",
    "    transformed_corners = np.dot(H, corners.T).T\n",
    "    transformed_corners /= transformed_corners[:, 2].reshape(-1, 1)\n",
    "\n",
    "    # Compute the bounding box of the transformed image\n",
    "    x_min, y_min = transformed_corners.min(axis=0)[:2]\n",
    "    x_max, y_max = transformed_corners.max(axis=0)[:2]\n",
    "    x_min, y_min = int(x_min), int(y_min)\n",
    "    x_max, y_max = int(np.ceil(x_max)), int(np.ceil(y_max))\n",
    "\n",
    "    # Dimensions for the output image\n",
    "    new_h = y_max - y_min\n",
    "    new_w = x_max - x_min\n",
    "\n",
    "    # Compute the inverse homography\n",
    "    H_inv = np.linalg.inv(H)\n",
    "\n",
    "    # Create mesh grid for the output image\n",
    "    x, y = np.meshgrid(np.arange(x_min, x_max), np.arange(y_min, y_max))\n",
    "    homogeneous_coords = np.stack((x.ravel(), y.ravel(), np.ones(y.size)))\n",
    "\n",
    "    # Map the output grid to the input image using the inverse homography\n",
    "    input_coords = np.dot(H_inv, homogeneous_coords)\n",
    "    input_coords /= input_coords[2]\n",
    "    input_x, input_y = input_coords[0], input_coords[1]\n",
    "\n",
    "    # Use interpolation to get pixel values\n",
    "    channels = [map_coordinates(im[..., i], [input_y, input_x], order=1) for i in range(im.shape[2])]\n",
    "    warped_img = np.stack(channels, axis=-1).reshape(new_h, new_w, im.shape[2])\n",
    "    \n",
    "    og_corners = [(0, 0), (h, w), (0, w), (h, 0)]\n",
    "    \n",
    "    saveImage(warped_img, name)\n",
    "\n",
    "    return warped_img, x_min, x_max, y_min, y_max\n",
    "\n",
    "# warped_im_left, oldX_min, oldX_max, oldY_min, oldY_max = warpImage(img_left, H, \"tesla_warped\")\n",
    "# plt.imshow(warped_im_left)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d077a1",
   "metadata": {},
   "source": [
    "## Image Rectification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda2fe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel coords: [top_left, top_right, bottom_right, bottom_left]\n",
    "\n",
    "car_correspondences = np.array([[592, 1408], [3600, 1960], [3720, 4000], [584, 4584]])\n",
    "rect_correspondences = np.array([[500, 1400], [3500, 1400], [3500, 4000], [500, 4000]])\n",
    "\n",
    "strokes_correspondences = np.array([[960, 2760], [2484, 1900], [3940, 2964], [2288, 4352]])\n",
    "square_correspondences = np.array([[1000, 2500], [3000, 2500], [3000, 4500], [1000, 4500]])\n",
    "\n",
    "img_car = skio.imread(\"data/car.jpg\") / 255\n",
    "img_strokes = skio.imread(\"data/strokes.jpg\") / 255\n",
    "\n",
    "H_car = computeH(car_correspondences, rect_correspondences)\n",
    "H_strokes = computeH(strokes_correspondences, square_correspondences)\n",
    "\n",
    "warped_car, _, _, _, _ = warpImage(img_car, H_car, \"car\")\n",
    "saveImage(warped_car, \"car\")\n",
    "warped_strokes, _, _, _, _ = warpImage(img_strokes, H_strokes, \"strokes\")\n",
    "saveImage(warped_strokes, \"strokes\")\n",
    "\n",
    "plt.figure(figsize=(10, 30))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(warped_car)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(warped_strokes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad51d7a",
   "metadata": {},
   "source": [
    "## Mosaicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cd212b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(h, w, im):\n",
    "    threshold = 0.0\n",
    "    mask = np.where(color.rgb2gray(im) > threshold, 1, 0)\n",
    "    return mask\n",
    "\n",
    "def create_mosaic(im1, im2, x_min, x_max, y_min, y_max):\n",
    "    # Calculate the final canvas size\n",
    "    canvas_width = im2.shape[1] + abs(x_min) + 10\n",
    "    canvas_height = max(im1.shape[0], im2.shape[0] + abs(y_min))\n",
    "    \n",
    "    # Create a black canvas with the calculated size\n",
    "    canvas1 = np.zeros((canvas_height, canvas_width, 3), dtype=np.uint8)\n",
    "    canvas2 = np.copy(canvas1)\n",
    "    \n",
    "    # Calculate the positions to place the images on the canvas\n",
    "    right_x_offset = max(0, x_max)\n",
    "    left_x_offset = max(0, abs(x_min))\n",
    "    y_offset = abs(y_min)\n",
    "    \n",
    "    # Paste the unwarped image on the canvas\n",
    "    canvas2[y_offset:y_offset + im2.shape[0], left_x_offset:left_x_offset + im2.shape[1]] = (im2 * 255).astype(np.uint8)\n",
    "    \n",
    "    # Place the warped image on the canvas\n",
    "    canvas1[:im1.shape[0], :im1.shape[1]] = (im1 * 255).astype(np.uint8)\n",
    "    \n",
    "    # Create masks\n",
    "    mask1 = create_mask(canvas1.shape[0], canvas1.shape[1], canvas1)   \n",
    "    mask2 = create_mask(canvas2.shape[0], canvas2.shape[1], canvas2)\n",
    "    \n",
    "    # Calculate overlapping region\n",
    "    blend_width = x_max\n",
    "    \n",
    "    # Normalize the overlap width to a range between 0 and 1\n",
    "    normalized_overlap = np.linspace(1, 0, blend_width)\n",
    "\n",
    "    blended_image = np.zeros((canvas_height, canvas_width, 3), dtype=np.uint8)\n",
    "\n",
    "    for y in range(canvas_height):\n",
    "        for x in range(canvas_width):\n",
    "            # Check if the pixel is within the overlap region (both masks are 1)\n",
    "            if mask1[y, x] == 1 and mask2[y, x] == 1:\n",
    "                left_weight = normalized_overlap[x - left_x_offset]\n",
    "                right_weight = 1 - left_weight\n",
    "                \n",
    "                # Perform blending for each channel (R, G, B)\n",
    "                for c in range(3):\n",
    "                    blended_image[y, x, c] = int(\n",
    "                        left_weight * canvas1[y, x, c] +\n",
    "                        right_weight * canvas2[y, x, c]\n",
    "                    )\n",
    "            elif mask1[y, x] == 0 and mask2[y, x] == 0:\n",
    "                blended_image[y, x] = 0\n",
    "            \n",
    "            elif mask1[y, x] != 0 and mask2[y, x] == 0:\n",
    "                blended_image[y, x] = canvas1[y, x]\n",
    "            else:\n",
    "                blended_image[y, x] = canvas2[y, x]\n",
    "                \n",
    "    return blended_image\n",
    "\n",
    "# blend = create_mosaic(warped_im_left, img_center, oldX_min, oldX_max, oldY_min, oldY_max)\n",
    "# plt.imshow(blend)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae83d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(imPath1, imPath2, correspondencePath, name):\n",
    "    # Read the images\n",
    "    im1 = skio.imread(imPath1) / 255\n",
    "    im2 = skio.imread(imPath2) / 255\n",
    "\n",
    "    # Get correspondences\n",
    "    with open(correspondencePath, 'r') as file:\n",
    "        correspondences = json.load(file)\n",
    "\n",
    "    im1Points = np.array(correspondences['im1Points'])\n",
    "    im2Points = np.array(correspondences['im2Points'])\n",
    "\n",
    "    # Fine tune correspondences\n",
    "    im2Points = np.array([fine_tune_correspondence(im1, im2, pt1, pt2) for pt1, pt2 in zip(im1Points, im2Points)])\n",
    "\n",
    "    # Compute the homography\n",
    "    H = computeH(im1Points, im2Points)\n",
    "\n",
    "    # Warp the images\n",
    "    warped_im1, x_min, x_max, y_min, y_max = warpImage(im1, H, name)\n",
    "\n",
    "    # Blend the images\n",
    "    mosaic = create_mosaic(warped_im1, im2, x_min, x_max, y_min, y_max)\n",
    "    \n",
    "    plt.imshow(mosaic)\n",
    "    plt.show()\n",
    "\n",
    "    # Save the mosaic\n",
    "    saveImage(mosaic, \"mosaic_\" + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d84aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizing large images captured by iPhone\n",
    "\n",
    "im1 = skio.imread(\"data/island_left.jpg\") / 255\n",
    "im2 = skio.imread(\"data/island_right.jpg\") / 255\n",
    "\n",
    "# Resize the images\n",
    "im1Resized = resizeImage(im1, 0.25)\n",
    "im2Resized = resizeImage(im2, 0.25)\n",
    "\n",
    "# Save the resized images\n",
    "skio.imsave(\"data/island_left_resized.jpg\", im1Resized)\n",
    "skio.imsave(\"data/island_right_resized.jpg\", im2Resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46ac8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "main(\"data/left_resized.jpg\", \"data/middle_resized.jpg\", \"left_resized_middle_resized.json\", \"Tesla\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990b4e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "main(\"data/building_left_resized.jpg\", \"data/building_right_resized.jpg\", \"building_left_resized_building_right_resized.json\", \"Building\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100ed162",
   "metadata": {},
   "outputs": [],
   "source": [
    "main(\"data/island_left_resized.jpg\", \"data/island_right_resized.jpg\", \"island_left_resized_island_right_resized.json\", \"Island\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de57792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "main(\"data/room_left_resized.jpg\", \"data/room_right_resized.jpg\", \"room_left_resized_room_right_resized.json\", \"Room\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59d0cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "main(\"data/corridor_left_resized.jpg\", \"data/corridor_right_resized.jpg\", \"corridor_left_resized_corridor_right_resized.json\", \"Corridor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3086583",
   "metadata": {},
   "source": [
    "# Part B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947ade11",
   "metadata": {},
   "source": [
    "## Detecting Corner Features in an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc49938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_harris_corners(im, edge_discard=20):\n",
    "    \"\"\"\n",
    "    This function takes a b&w image and an optional amount to discard\n",
    "    on the edge (default is 5 pixels), and finds all harris corners\n",
    "    in the image. Harris corners near the edge are discarded and the\n",
    "    coordinates of the remaining corners are returned. A 2d array (h)\n",
    "    containing the h value of every pixel is also returned.\n",
    "\n",
    "    h is the same shape as the original image, im.\n",
    "    coords is 2 x n (ys, xs).\n",
    "    \"\"\"\n",
    "\n",
    "    assert edge_discard >= 20\n",
    "\n",
    "    # find harris corners\n",
    "    h = corner_harris(im, method='eps', sigma=1)\n",
    "    coords = peak_local_max(h, min_distance=1)\n",
    "\n",
    "    # discard points on edge\n",
    "    edge = edge_discard  # pixels\n",
    "    mask = (coords[:, 0] > edge) & \\\n",
    "           (coords[:, 0] < im.shape[0] - edge) & \\\n",
    "           (coords[:, 1] > edge) & \\\n",
    "           (coords[:, 1] < im.shape[1] - edge)\n",
    "    coords = coords[mask].T\n",
    "    return h, coords\n",
    "\n",
    "def dist2(x, c):\n",
    "    \"\"\"\n",
    "    dist2 Calculates squared distance between two sets of points.\n",
    "\n",
    "    Description\n",
    "    D = DIST2(X, C) takes two matrices of vectors and calculates the\n",
    "    squared Euclidean distance between them.  Both matrices must be of\n",
    "    the same column dimension.  If X has M rows and N columns, and C has\n",
    "    L rows and N columns, then the result has M rows and L columns.  The\n",
    "    I, Jth entry is the  squared distance from the Ith row of X to the\n",
    "    Jth row of C.\n",
    "\n",
    "    Adapted from code by Christopher M Bishop and Ian T Nabney.\n",
    "    \"\"\"\n",
    "    \n",
    "    ndata, dimx = x.shape\n",
    "    ncenters, dimc = c.shape\n",
    "    assert(dimx == dimc, 'Data dimension does not match dimension of centers')\n",
    "\n",
    "    return (np.ones((ncenters, 1)) * np.sum((x**2).T, axis=0)).T + \\\n",
    "            np.ones((   ndata, 1)) * np.sum((c**2).T, axis=0)    - \\\n",
    "            2 * np.inner(x, c)\n",
    "\n",
    "def overlay_harris_corners(image, corner_points):\n",
    "    img_with_corners = np.copy(image)\n",
    "    for x, y in corner_points.T:\n",
    "        cv2.circle(img_with_corners, (int(y), int(x)), 5, (0, 0, 255), -1)  # Draw a red circle\n",
    "    return img_with_corners\n",
    "\n",
    "def draw_correspondence_lines(img1, img2, points1, points2):\n",
    "    concatenated = np.hstack((img1, img2))\n",
    "    \n",
    "    line_color = (0, 255, 0)\n",
    "    line_thickness = 2  \n",
    "    point_color = (0, 0, 255)\n",
    "    point_radius = 3\n",
    "    point_thickness = -1\n",
    "\n",
    "    for pt1, pt2 in zip(points1, points2):\n",
    "        start_point = tuple(pt1.astype(int))\n",
    "        end_point = tuple((pt2 + [img1.shape[1], 0]).astype(int)) \n",
    "        concatenated = cv2.line(concatenated, start_point, end_point, line_color, line_thickness)\n",
    "        \n",
    "        concatenated = cv2.circle(concatenated, start_point, point_radius, point_color, point_thickness)\n",
    "        concatenated = cv2.circle(concatenated, end_point, point_radius, point_color, point_thickness)\n",
    "        \n",
    "    return concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b283fedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = skio.imread(\"data/building_left_resized.jpg\") / 255\n",
    "im2 = skio.imread(\"data/building_right_resized.jpg\") / 255\n",
    "\n",
    "h1, corners1 = get_harris_corners(color.rgb2gray(im1))\n",
    "h2, corners2 = get_harris_corners(color.rgb2gray(im2))\n",
    "\n",
    "overlaid_im1 = overlay_harris_corners(im1, corners1)\n",
    "overlaid_im2 = overlay_harris_corners(im2, corners2)\n",
    "\n",
    "plt.imshow(overlaid_im1)\n",
    "plt.show()\n",
    "plt.imshow(overlaid_im2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b5371e",
   "metadata": {},
   "source": [
    "## Adaptive Non-Maximal Suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04987c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_non_maximal_suppression(corner_strength, corners, nip, robustness_factor, min_radius):\n",
    "    # Create a 2D array where each row is a repeat of the corner strengths\n",
    "    strengths_2D = corner_strength[corners[0], corners[1]].reshape(-1, 1)\n",
    "\n",
    "    # Create a boolean mask for the other strengths greater than the robustness factor times the current strength\n",
    "    mask = strengths_2D.T > robustness_factor * strengths_2D\n",
    "\n",
    "    # Use the distance matrix you already compute elsewhere\n",
    "    distance_matrix = dist2(corners.T, corners.T)\n",
    "\n",
    "    # Mask out irrelevant distances\n",
    "    masked_distances = np.where(mask, distance_matrix, np.inf)\n",
    "    \n",
    "    # Set diagonal to infinity to avoid self-distance\n",
    "    np.fill_diagonal(masked_distances, np.inf)\n",
    "\n",
    "    # Get the minimum distance for each corner (i.e., the suppression radius)\n",
    "    radii = np.min(masked_distances, axis=1)\n",
    "    \n",
    "    # Ensure radii values are at least min_radius\n",
    "    radii = np.maximum(radii, min_radius)\n",
    "    \n",
    "    # Sort the corners based on radii\n",
    "    sorted_corners_indices = np.argsort(radii)[::-1]  # Indices of corners sorted by radii in descending order\n",
    "    suppressed_corners = corners[:, sorted_corners_indices[:nip]]\n",
    "    \n",
    "    return suppressed_corners\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907af7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_points1 = adaptive_non_maximal_suppression(h1, corners1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72300ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_points2 = adaptive_non_maximal_suppression(h2, corners2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b4af20",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlaid_selected_im1 = overlay_harris_corners(im1, selected_points1)\n",
    "overlaid_selected_im2 = overlay_harris_corners(im2, selected_points2)\n",
    "\n",
    "plt.imshow(overlaid_selected_im1)\n",
    "plt.show()\n",
    "plt.imshow(overlaid_selected_im2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248abd0c",
   "metadata": {},
   "source": [
    "## Extracting Feature Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c0e903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_descriptor(image, interest_point, out_patch_size=8, in_patch_size=40):\n",
    "    \n",
    "    x, y = interest_point\n",
    "    half_width = in_patch_size // 2\n",
    "\n",
    "    # Extract 8 x 8 patch from the larger 40 x 40 patch\n",
    "    large_patch = image[y - half_width:y + half_width, x - half_width:x + half_width]\n",
    "    patch = cv2.resize(large_patch, (out_patch_size, out_patch_size), interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    # Bias/Gain normalization \n",
    "    patch = (patch - np.mean(patch)) / (np.std(patch) + 1e-8)\n",
    "    \n",
    "    return patch\n",
    "\n",
    "def feature_descriptors(im, points, mode=\"easy\"):\n",
    "    if mode==\"easy\":\n",
    "        output = [extract_descriptor((im), (x, y)) for y, x in points.T]\n",
    "    else:\n",
    "        output = [extract_rotation_invariant_descriptor(im, (x, y)) for y, x in points.T]\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca828e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors1 = feature_descriptors(color.rgb2gray(im1), selected_points1)\n",
    "descriptors2 = feature_descriptors(color.rgb2gray(im2), selected_points2)\n",
    "print(descriptors1[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321fa1ab",
   "metadata": {},
   "source": [
    "## Feature Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81274f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance(descriptor1, descriptor2):\n",
    "    return np.linalg.norm(descriptor1 - descriptor2)\n",
    "\n",
    "def match_features(descriptors1, descriptors2, threshold):\n",
    "    good_matches = {}\n",
    "    for i, d1 in enumerate(descriptors1):\n",
    "        distances = [(j, compute_distance(d1, d2)) for j, d2 in enumerate(descriptors2)]\n",
    "        sorted_distances = sorted(distances, key=lambda x: x[1])\n",
    "        nn2 = sorted_distances[:2]\n",
    "        if nn2[0][1] < threshold * nn2[1][1]:\n",
    "            # Index i from descriptor1 matched to index j from descriptor2\n",
    "            good_matches[i] = nn2[0][0]\n",
    "            \n",
    "    return good_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5943232",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = match_features(descriptors1, descriptors2, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a71adca",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_points1 = selected_points1.T[list(matches.keys())]\n",
    "extracted_points2 = selected_points2.T[list(matches.values())]\n",
    "\n",
    "overlaid_extracted_im1 = overlay_harris_corners(im1, extracted_points1.T)\n",
    "overlaid_extracted_im2 = overlay_harris_corners(im2, extracted_points2.T)\n",
    "concat = draw_correspondence_lines(im1, im2, np.fliplr(extracted_points1), np.fliplr(extracted_points2))\n",
    "\n",
    "plt.imshow(overlaid_extracted_im1)\n",
    "plt.show()\n",
    "plt.imshow(overlaid_extracted_im2)\n",
    "plt.show()\n",
    "plt.imshow(concat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3e485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(extracted_points1)\n",
    "print(extracted_points2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe560506",
   "metadata": {},
   "source": [
    "## RANSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba6d88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ransac(pts_warp, pts_ref, N, epsilon=8):\n",
    "    pts_warp_flip, pts_ref_flip = np.fliplr(pts_warp), np.fliplr(pts_ref)\n",
    "    \n",
    "    max_inliers = 0\n",
    "    best_inliers = None\n",
    "    \n",
    "    for _ in range(N):\n",
    "        num_inliers = 0\n",
    "        inliers = []\n",
    "        \n",
    "        random_indices = np.random.choice(pts_warp_flip.shape[0], 4, replace=False)\n",
    "        select_points1 = pts_warp_flip[random_indices]\n",
    "        select_points2 = pts_ref_flip[random_indices]\n",
    "        H = computeH(select_points1, select_points2)\n",
    "        for i in range(len(pts_warp_flip)):\n",
    "            homogeneous_point = np.append(pts_warp_flip[i], 1)\n",
    "            transformed_point = H @ np.array(homogeneous_point)\n",
    "            transformed_point_2d = transformed_point[:2] / transformed_point[2]\n",
    "            distance = np.linalg.norm(transformed_point_2d - pts_ref_flip[i])\n",
    "            if distance < epsilon:\n",
    "                num_inliers += 1\n",
    "                inliers.append(i)\n",
    "        if num_inliers > max_inliers:\n",
    "            best_inliers = inliers\n",
    "            max_inliers = num_inliers\n",
    "        \n",
    "    print(best_inliers, max_inliers)\n",
    "            \n",
    "    return best_inliers\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8233c04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"building_left_resized_building_right_resized.json\", 'r') as file:\n",
    "    correspondences = json.load(file)\n",
    "\n",
    "im1Points = np.array(correspondences['im1Points'])\n",
    "im2Points = np.array(correspondences['im2Points'])\n",
    "\n",
    "# Fine tune correspondences\n",
    "im2Points = np.array([fine_tune_correspondence(im1, im2, pt1, pt2) for pt1, pt2 in zip(im1Points, im2Points)])\n",
    "im1Points, im2Points = np.fliplr(im1Points), np.fliplr(im2Points)\n",
    "print(im1Points)\n",
    "\n",
    "inliers = ransac(im1Points, im2Points, 50)\n",
    "# To get correspondence points in (x, y) instead of (y, x)\n",
    "correspondences1, correspondences2 = np.fliplr(im1Points[inliers]), np.fliplr(im2Points[inliers])\n",
    "# print(correspondences1, correspondences2)\n",
    "H = computeH(correspondences1, correspondences2)\n",
    "# print(H)\n",
    "warped_im1, x_min, x_max, y_min, y_max = warpImage(im1, H, \"Tesla2\")\n",
    "plt.imshow(warped_im1)\n",
    "plt.show()\n",
    "mosaic = create_mosaic(warped_im1, im2, x_min, x_max, y_min, y_max)\n",
    "    \n",
    "plt.imshow(mosaic)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860fb162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(im1, im2, name, nip, robustness_factor, min_radius, threshold, epsilon):\n",
    "    # Get and display Harris corners\n",
    "    h1, corners1 = get_harris_corners(color.rgb2gray(im1))\n",
    "    h2, corners2 = get_harris_corners(color.rgb2gray(im2))\n",
    "\n",
    "    overlaid_im1 = overlay_harris_corners((im1*255).astype(np.uint8), corners1)\n",
    "    overlaid_im2 = overlay_harris_corners((im2*255).astype(np.uint8), corners2)\n",
    "\n",
    "    plt.imshow(overlaid_im1)\n",
    "    plt.show()\n",
    "    plt.imshow(overlaid_im2)\n",
    "    plt.show()\n",
    "    \n",
    "    saveImage(overlaid_im1, name + \"_harris1\")\n",
    "    saveImage(overlaid_im2, name + \"_harris2\")\n",
    "    \n",
    "    # ANMS\n",
    "    selected_points1 = adaptive_non_maximal_suppression(h1, corners1, nip=nip, \n",
    "                                                        robustness_factor=robustness_factor, min_radius=min_radius)\n",
    "    selected_points2 = adaptive_non_maximal_suppression(h2, corners2, nip=nip, \n",
    "                                                        robustness_factor=robustness_factor, min_radius=min_radius)\n",
    "    \n",
    "    overlaid_selected_im1 = overlay_harris_corners((im1*255).astype(np.uint8), selected_points1)\n",
    "    overlaid_selected_im2 = overlay_harris_corners((im2*255).astype(np.uint8), selected_points2)\n",
    "\n",
    "    plt.imshow(overlaid_selected_im1)\n",
    "    plt.show()\n",
    "    plt.imshow(overlaid_selected_im2)\n",
    "    plt.show()\n",
    "    \n",
    "    saveImage(overlaid_selected_im1, name + \"_anms1\")\n",
    "    saveImage(overlaid_selected_im2, name + \"_anms2\")\n",
    "    \n",
    "    # Feature Descriptors\n",
    "    descriptors1 = feature_descriptors(color.rgb2gray(im1), selected_points1)\n",
    "    descriptors2 = feature_descriptors(color.rgb2gray(im2), selected_points2)\n",
    "    plt.imshow(descriptors1[0], cmap=\"gray\")\n",
    "    plt.show()\n",
    "    \n",
    "    for i in range(4):\n",
    "        saveDescriptor(descriptors1[i], name + \"_descriptor\" + str(i))\n",
    "    \n",
    "    # Feature Matching\n",
    "    matches = match_features(descriptors1, descriptors2, threshold=threshold)\n",
    "    print(len(matches))\n",
    "    extracted_points1 = selected_points1.T[list(matches.keys())]\n",
    "    extracted_points2 = selected_points2.T[list(matches.values())]\n",
    "\n",
    "    concat = draw_correspondence_lines((im1*255).astype(np.uint8), (im2*255).astype(np.uint8), np.fliplr(extracted_points1), np.fliplr(extracted_points2))\n",
    "    \n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(concat)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(\"output/\" + name + \"_matching.jpg\", bbox_inches='tight', pad_inches=0)\n",
    "    plt.show()\n",
    "    \n",
    "    # RANSAC, Mosaic\n",
    "    inliers = ransac(extracted_points1, extracted_points2, 10000, epsilon=epsilon)\n",
    "    # To get correspondence points in (x, y) instead of (y, x)\n",
    "    correspondences1, correspondences2 = np.fliplr(extracted_points1[inliers]), np.fliplr(extracted_points2[inliers])\n",
    "    concat = draw_correspondence_lines((im1*255).astype(np.uint8), (im2*255).astype(np.uint8), correspondences1, correspondences2)\n",
    "    \n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(concat)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(\"output/\" + name + \"_ransac.jpg\", bbox_inches='tight', pad_inches=0)\n",
    "    plt.show()\n",
    "    \n",
    "    H = computeH(correspondences1, correspondences2)\n",
    "    warped_im1, x_min, x_max, y_min, y_max = warpImage(im1, H, name)\n",
    "    plt.imshow(warped_im1)\n",
    "    plt.show()\n",
    "    mosaic = create_mosaic(warped_im1, im2, x_min, x_max, y_min, y_max)\n",
    "\n",
    "    plt.imshow(mosaic)\n",
    "    plt.show()\n",
    "    \n",
    "    saveImage(mosaic, name + \"_mosaic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b73a81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "im1 = skio.imread(\"data/room_left_resized.jpg\") / 255\n",
    "im2 = skio.imread(\"data/room_right_resized.jpg\") / 255\n",
    "\n",
    "main(im1, im2, \"Room2\", 250, 0.9, 1000, 0.6, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db273b2a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "im1 = skio.imread(\"data/island_left_resized.jpg\") / 255\n",
    "im2 = skio.imread(\"data/island_right_resized.jpg\") / 255\n",
    "\n",
    "main(im1, im2, \"Island2\", 300, 0.9, 1000, 0.6, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e417f463",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "im1 = skio.imread(\"data/corridor_left_resized.jpg\") / 255\n",
    "im2 = skio.imread(\"data/corridor_right_resized.jpg\") / 255\n",
    "\n",
    "main(im1, im2, \"Corridor2\", 500, 0.9, 1000, 0.5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c963d5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizing large images captured by iPhone\n",
    "\n",
    "im1 = skio.imread(\"data/room_left.jpg\") / 255\n",
    "im2 = skio.imread(\"data/room_right.jpg\") / 255\n",
    "\n",
    "# Resize the images\n",
    "im1Resized = resizeImage(im1, 0.25)\n",
    "im2Resized = resizeImage(im2, 0.25)\n",
    "\n",
    "# Save the resized images\n",
    "skio.imsave(\"data/room_left_resized.jpg\", im1Resized)\n",
    "skio.imsave(\"data/room_right_resized.jpg\", im2Resized)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
