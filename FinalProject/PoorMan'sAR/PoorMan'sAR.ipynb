{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc3b382",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade scipy\n",
    "!pip install scikit-video\n",
    "!pip install ffmpeg-python\n",
    "!pip install scikit-image\n",
    "!pip uninstall opencv-python opencv-contrib-python -y\n",
    "!pip install opencv-contrib-python\n",
    "!pip install pyrender trimesh imageio\n",
    "!pip install PyOpenGL PyOpenGL_accelerate\n",
    "!pip install numpy==1.20.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cada0ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skvideo.io\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pyrender\n",
    "import trimesh\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06723b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4271669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the video and frames as images, normalized\n",
    "path = 'Data/IMG_3862.mp4'\n",
    "video = skvideo.io.vreader(path)\n",
    "\n",
    "frames = []\n",
    "for frame in video:\n",
    "    frames.append(frame)\n",
    "    \n",
    "print(\"# frames: \", len(frames))\n",
    "print(\"Frame shape: \", frames[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b53c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing keypoints and world coordinate representation\n",
    "image = frames[0]\n",
    "# io.imsave(\"firstFrame.jpg\", image)\n",
    "\n",
    "# Manually selecting 2D/ 3D points in (x, y)/ (x, y, z) format\n",
    "points2d = [(333, 1271), (323, 1205), (320, 1130), \n",
    "            (252, 1174), (242, 1105), (239, 1039), \n",
    "            (484, 1195), (482, 1139), (473, 1057), (622, 1127), (621, 1072), (614, 994), (747, 1067), (751, 1014), (746, 935),\n",
    "            (381, 975), (305, 900), (167, 957), (516, 919), (433, 850), (648, 865), (560, 802)]\n",
    "\n",
    "points3d = [(0.0, 0.0, 0.0), (0.0, 0.0, 1.5), (0.0, 0.0, 3.0),\n",
    "           (0.0, 3.0, 0.0), (0.0, 3.0, 1.5), (0.0, 3.0, 3.0),\n",
    "           (3.0, 0.0, 0.0), (3.0, 0.0, 1.5), (3.0, 0.0, 3.0), (6.0, 0.0, 0.0), (6.0, 0.0, 1.5), (6.0, 0.0, 3.0), (9.0, 0.0, 0.0), (9.0, 0.0, 1.5), (9.0, 0.0, 3.0),\n",
    "           (3.0, 3.0, 3.0), (3.0, 6.0, 3.0), (0.0, 6.0, 3.0), (6.0, 3.0, 3.0), (6.0, 6.0, 3.0), (9.0, 3.0, 3.0), (9.0, 6.0, 3.0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcbf2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(points2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1e5a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing tracking\n",
    "def get_patch(point, patch_size=8):\n",
    "    x_top_left = int(point[0] - patch_size / 2)\n",
    "    y_top_left = int(point[1] - patch_size / 2)\n",
    "    \n",
    "    return (x_top_left, y_top_left, patch_size, patch_size)\n",
    "\n",
    "trackers = [cv2.legacy.TrackerMedianFlow_create() for _ in points2d]\n",
    "first_frame_bgr = cv2.cvtColor(frames[0], cv2.COLOR_RGB2BGR)\n",
    "for point, tracker in zip(points2d, trackers):\n",
    "    patch = get_patch(point)\n",
    "    tracker.init(first_frame_bgr, patch)\n",
    "\n",
    "updated_trackers = [points2d]\n",
    "for frame in frames[1:]:\n",
    "    frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "    frame_points = []\n",
    "    for tracker in trackers:\n",
    "        success, patch = tracker.update(frame_bgr)\n",
    "        if success:\n",
    "            x_center = int(patch[0] + patch[2] / 2)\n",
    "            y_center = int(patch[1] + patch[3] / 2)\n",
    "            frame_points.append((x_center, y_center))\n",
    "        else:\n",
    "            frame_points.append(None)\n",
    "            \n",
    "    updated_trackers.append(frame_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad64ef25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(updated_trackers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733e4e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating tracking video\n",
    "def create_tracking_video(frames, tracked_points, out_path, fps=30):\n",
    "    height, width, _ = frames[0].shape\n",
    "    \n",
    "    writer = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "    \n",
    "    for frame, pts in zip(frames, tracked_points):\n",
    "        for point in pts:\n",
    "            if point is not None:\n",
    "                cv2.circle(frame, (int(point[0]), int(point[1])), 5, (0, 255, 0), -1)\n",
    "                \n",
    "        frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        writer.write(frame_bgr)\n",
    "        \n",
    "    writer.release()\n",
    "    \n",
    "create_tracking_video(frames, updated_trackers, 'Output/tracking.mp4')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aca827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camera calibration\n",
    "def solve_projection_matrix(points2D, points3D):\n",
    "    A = []\n",
    "    B = []\n",
    "\n",
    "    # Only use points that are successfully tracked\n",
    "    valid_points = [(p2d, p3d) for p2d, p3d in zip(points2D, points3D) if p2d is not None]\n",
    "\n",
    "    for p2d, p3d in valid_points:\n",
    "        X, Y, Z = p3d\n",
    "        u, v = p2d\n",
    "        \n",
    "        A.append([X, Y, Z, 1, 0, 0, 0, 0, -u*X, -u*Y, -u*Z])\n",
    "        B.append(u)\n",
    "        \n",
    "        A.append([0, 0, 0, 0, X, Y, Z, 1, -v*X, -v*Y, -v*Z])\n",
    "        B.append(v)\n",
    "        \n",
    "    A = np.array(A)\n",
    "    B = np.array(B)\n",
    "\n",
    "    projection_matrix, _, _, _ = np.linalg.lstsq(A, B, rcond=None)\n",
    "    projection_matrix = np.append(projection_matrix, 1).reshape(3, 4)\n",
    "    \n",
    "    return projection_matrix\n",
    "\n",
    "projection_matrices = [solve_projection_matrix(frame_points, points3d) for frame_points in updated_trackers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7904a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(projection_matrices[0])\n",
    "print(projection_matrices[1])\n",
    "print(len(projection_matrices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3586677e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projecting cube onto scene\n",
    "axis_pts = np.float32([[0,0,3], [0,3,3], [3,3,3], [3,0,3],\n",
    "                      [0,0,6], [0,3,6], [3,3,6], [3,0,6]])\n",
    "\n",
    "def draw(img, imgpts):\n",
    "    imgpts = np.int32(imgpts).reshape(-1,2)\n",
    "    # draw ground floor in green\n",
    "    img = cv2.drawContours(img, [imgpts[:4]],-1,(0,255,0),-3)\n",
    "    # draw pillars in blue color\n",
    "    for i,j in zip(range(4),range(4,8)):\n",
    "        img = cv2.line(img, tuple(imgpts[i]), tuple(imgpts[j]),(255),3)\n",
    "    # draw top layer in red color\n",
    "    img = cv2.drawContours(img, [imgpts[4:]],-1,(0,0,255),3)\n",
    "    return img\n",
    "\n",
    "def project_points(axis_pts, projection_matrix):\n",
    "    # Convert to homogenous coordinates by adding a row of 1s\n",
    "    ones = np.ones((axis_pts.shape[0], 1))\n",
    "    homogenous_axis_pts = np.hstack([axis_pts, ones])\n",
    "\n",
    "    # Apply the projection matrix\n",
    "    projected_pts = np.dot(projection_matrix, homogenous_axis_pts.T).T\n",
    "\n",
    "    # Convert back to non-homogenous coordinates\n",
    "    projected_pts = projected_pts[:, :2] / projected_pts[:, 2, np.newaxis]\n",
    "\n",
    "    return projected_pts\n",
    "\n",
    "\n",
    "def create_cube_video(frames, axis_pts, projection_matrices, output_path, fps=30):\n",
    "    height, width, _ = frames[0].shape\n",
    "    video_writer = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
    "\n",
    "    for frame, proj_matrix in zip(frames, projection_matrices):\n",
    "        projected_pts = project_points(axis_pts, proj_matrix)\n",
    "        frame_with_cube = draw(frame.copy(), projected_pts)\n",
    "        video_writer.write(frame_with_cube)\n",
    "\n",
    "    video_writer.release()\n",
    "\n",
    "create_cube_video(frames, axis_pts, projection_matrices, 'Output/cube.mp4')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7d6054",
   "metadata": {},
   "source": [
    "# Bells and Whistles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8231f7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the video and frames as images, normalized\n",
    "path = 'Data/IMG_3862.mp4'\n",
    "video = skvideo.io.vreader(path)\n",
    "\n",
    "frames = []\n",
    "for frame in video:\n",
    "    frames.append(frame)\n",
    "    \n",
    "print(\"# frames: \", len(frames))\n",
    "print(\"Frame shape: \", frames[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ac439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading mesh and setting up render\n",
    "duck_path = 'Data/Duck.glb'\n",
    "duck = trimesh.load(duck_path, file_type='glb')\n",
    "duckmesh = pyrender.Mesh.from_trimesh(list(duck.geometry.values())[0])\n",
    "\n",
    "scene = pyrender.Scene()\n",
    "scene.add(duckmesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b88a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_frames(original_frame, rendered_frame):\n",
    "    alpha = 0.5\n",
    "    # rendered_frame = cv2.resize(rendered_frame, (original_frame.shape[1], original_frame.shape[0]))\n",
    "\n",
    "    # Blend the two images\n",
    "    combined_frame = cv2.addWeighted(original_frame, 1 - alpha, rendered_frame, alpha, 0)\n",
    "\n",
    "    return combined_frame\n",
    "\n",
    "def save_video(frames, output_path, fps=30, frame_size=(1080, 1920)):\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  \n",
    "    video = cv2.VideoWriter(output_path, fourcc, fps, frame_size)\n",
    "\n",
    "    for frame in frames:\n",
    "        video.write(frame)\n",
    "\n",
    "    video.release()\n",
    "\n",
    "renderer = pyrender.OffscreenRenderer(viewport_width=1080, viewport_height=1920)\n",
    "rendered_frames = []\n",
    "for i, P in enumerate(projection_matrices):\n",
    "    \n",
    "    # Decomposing projection matrix\n",
    "    K, R, t, _, _, _, _ = cv2.decomposeProjectionMatrix(P)\n",
    "    t = ((t / t[3])[:3]).reshape(3)\n",
    "    K = K[:3, :3]\n",
    "    \n",
    "    camera = pyrender.IntrinsicsCamera(fx=K[0, 0], fy=K[1, 1], cx=K[0, 2], cy=K[1, 2])\n",
    "    \n",
    "    # The extrinsic matrix is the camera pose\n",
    "    camera_pose = np.eye(4)\n",
    "    camera_pose[:3, :3] = R\n",
    "    camera_pose[:3, 3] = t.squeeze()\n",
    "    \n",
    "    scene.add(camera, pose=camera_pose)\n",
    "    color, _ = renderer.render(scene)\n",
    "    \n",
    "    combined_frame = overlay_frames(frames[i], color)\n",
    "    rendered_frames.append(combined_frame)\n",
    "    \n",
    "    scene.remove_node(camera)\n",
    "    \n",
    "save_video(rendered_frames, 'Output/duck.mp4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
