{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V100","authorship_tag":"ABX9TyPbM12/0txu6V0g5S0ENOUY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Final Project 1: A Neural Algorithm of Artistic Style"],"metadata":{"id":"BFpY13wHVGsh"}},{"cell_type":"markdown","source":["## Dependencies"],"metadata":{"id":"jvRUatGAVSGd"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"blpiO28jU37s","executionInfo":{"status":"ok","timestamp":1701896583559,"user_tz":480,"elapsed":6435,"user":{"displayName":"Aryaman Darda","userId":"14371288459896692165"}}},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","import math\n","import copy\n","from tqdm import tqdm\n","from PIL import Image"]},{"cell_type":"code","source":["# Mounting Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6S3mCkZ-Vih4","executionInfo":{"status":"ok","timestamp":1701896605796,"user_tz":480,"elapsed":22244,"user":{"displayName":"Aryaman Darda","userId":"14371288459896692165"}},"outputId":"bb4ced00-0037-4f59-86cb-34fbaf9ad49a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qcjpGZ-MLyt3","executionInfo":{"status":"ok","timestamp":1701896605796,"user_tz":480,"elapsed":3,"user":{"displayName":"Aryaman Darda","userId":"14371288459896692165"}},"outputId":"baf92512-b04d-4661-dc88-0eaaec184a80"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["## Defining Model"],"metadata":{"id":"-HS-xwLxgVcL"}},{"cell_type":"code","source":["# Set the device to GPU if available, otherwise use CPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Load and preprocess content and style images\n","def load_image(image_path, image_size=None):\n","    transform = transforms.Compose([\n","        transforms.Resize(image_size) if image_size is not None else transforms.Resize(512),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","    ])\n","    image = Image.open(image_path).convert(\"RGB\")\n","    image = transform(image).unsqueeze(0).to(device)\n","    return image\n","\n","content_image = load_image(\"/content/drive/MyDrive/Projects/CS180FinalProj1/Data/campanile.jpg\", image_size=(512, 512))\n","style_image = load_image(\"/content/drive/MyDrive/Projects/CS180FinalProj1/Data/basquiat.jpg\", image_size=(512, 512))\n","\n","# Display the content and style images\n","def imshow(tensor, title=None, show=False, save_fig=False, save_path=\"\"):\n","    tensor = tensor.squeeze(0).detach().cpu()\n","\n","    inv_normalize = transforms.Normalize(\n","        mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n","        std=[1/0.229, 1/0.224, 1/0.225]\n","    )\n","    tensor = inv_normalize(tensor)\n","\n","    tensor.clamp_(0, 1)\n","\n","    image = transforms.ToPILImage()(tensor)\n","\n","    plt.imshow(image)\n","    plt.axis(\"off\")\n","    if title is not None:\n","        plt.title(title)\n","    if save_fig:\n","        plt.savefig(save_path, bbox_inches='tight', pad_inches=0)\n","    if show:\n","        plt.show()\n","\n","\n","plt.figure(figsize=(10, 5))\n","plt.subplot(1, 2, 1)\n","imshow(content_image, title=\"Content Image\")\n","\n","plt.subplot(1, 2, 2)\n","imshow(style_image, title=\"Style Image\")\n","plt.show()\n","\n","# Define the VGG19 model with modified layers for feature extraction\n","class VGG19Features(nn.Module):\n","    def __init__(self, avg_pool: bool=False):\n","        super(VGG19Features, self).__init__()\n","        vgg19_layers = models.vgg19(pretrained=True).features\n","        print(vgg19_layers)\n","\n","        if avg_pool:\n","            vgg19_layers = nn.Sequential(*[nn.AvgPool2d(2) if isinstance(x, nn.MaxPool2d) else x for x in vgg19_layers])\n","\n","        self.slice1 = nn.Sequential()\n","        self.slice2 = nn.Sequential()\n","        self.slice3 = nn.Sequential()\n","        self.slice4 = nn.Sequential()\n","        self.slice5 = nn.Sequential()\n","\n","        for x in range(1):\n","            self.slice1.add_module(str(x), vgg19_layers[x])\n","        for x in range(1, 6):\n","            self.slice2.add_module(str(x), vgg19_layers[x])\n","        for x in range(6, 11):\n","            self.slice3.add_module(str(x), vgg19_layers[x])\n","        for x in range(11, 20):\n","            self.slice4.add_module(str(x), vgg19_layers[x])\n","        for x in range(20, 29):\n","            self.slice5.add_module(str(x), vgg19_layers[x])\n","\n","        for p in self.parameters():\n","            p.requires_grad = False\n","\n","        self.eval()\n","\n","    def forward(self, x):\n","        h1 = self.slice1(x)\n","        h2 = self.slice2(h1)\n","        h3 = self.slice3(h2)\n","        h4 = self.slice4(h3)\n","        h5 = self.slice5(h4)\n","\n","        return [h1, h2, h3, h4, h5]\n","\n","# Define content loss and style loss functions\n","def gram_matrix(input):\n","    n, c, h, w = input.shape\n","    x = input.view(n, c, h * w)\n","    y = input.view(n, c, h * w).permute(0, 2, 1)\n","    gram = torch.bmm(x, y) / (h * w)\n","\n","    return gram\n","\n","def calc_content_loss(input_features, target_features, weights):\n","    total_loss = torch.tensor(0.0, dtype=torch.float32).to(device)\n","    num_feats = len(input_features)\n","    for i in range(num_feats):\n","        block_loss = F.mse_loss(input_features[i], target_features[i])\n","        total_loss += block_loss * weights[i]\n","\n","    return total_loss\n","\n","def calc_style_loss(input_features, target_features, weights):\n","    total_loss = torch.tensor(0.0, dtype=torch.float32).to(device)\n","    num_feats = len(input_features)\n","    for i in range(num_feats):\n","        gram_input = gram_matrix(input_features[i])\n","        gram_target = gram_matrix(target_features[i])\n","        block_loss = F.mse_loss(gram_input, gram_target)\n","        total_loss += block_loss * weights[i]\n","\n","    return total_loss\n","\n","# Initialize the generated image with content image or random noise\n","input_image = content_image.clone().requires_grad_(True)\n","\n","# Set the hyperparameters\n","style_weight = 1000000   # Weight for the style loss\n","content_weight = 1     # Weight for the content loss\n","lr = 0.1              # Learning rate\n","iterations = 2000       # Number of iterations\n","content_slice_weights = (0.0, 0.0, 0.0, 0.0, 1.0)    # Weights for each content layer\n","style_slice_weights = (0.2, 0.2, 0.2, 0.2, 0.2)      # Weights for each style layer\n","\n","# Initializations\n","vgg = VGG19Features(avg_pool=True).to(device)\n","optimizer = optim.Adam([input_image], lr=lr)\n","\n","with torch.no_grad():\n","    content_features = vgg(content_image)\n","    style_features = vgg(style_image)\n","\n","# Training Loop\n","prog_bar = tqdm(range(1, iterations + 1))\n","for i in prog_bar:\n","    input_features = vgg(input_image)\n","    content_loss = calc_content_loss(input_features, content_features, content_slice_weights)\n","    style_loss = calc_style_loss(input_features, style_features, style_slice_weights)\n","    loss = content_weight * content_loss + style_weight * style_loss\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    # with torch.no_grad():\n","        # input_image.clamp_(0, 1)\n","    if (i + 1) % 200 == 0 or i == 0:\n","        imshow(input_image, show=True, save_fig=True, save_path=f\"/content/drive/MyDrive/Projects/CS180FinalProj1/Output/campanile_basquiat_{i}.jpg\")\n","    prog_bar.set_description(f\"Iteration [{i}/{iterations}] Loss: {loss.item():.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1KfbM0wuoTA8fAsrA7KKu4eHLAsCFA3OE"},"id":"OAfcUx3PHspl","executionInfo":{"status":"ok","timestamp":1701899856238,"user_tz":480,"elapsed":97877,"user":{"displayName":"Aryaman Darda","userId":"14371288459896692165"}},"outputId":"011df516-621c-4771-b00e-ee05e9e3ac54"},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}